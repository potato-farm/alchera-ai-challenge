{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Segmentation_Train.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvsblZ0NyZIM"
      },
      "source": [
        "!pip install wandb\n",
        "import wandb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOoIOTLawWt7"
      },
      "source": [
        "import os\n",
        "import random\n",
        "import time\n",
        "import json\n",
        "import warnings \n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from utils import label_accuracy_score, add_hist\n",
        "import cv2\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "from pycocotools.coco import COCO\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "print('pytorch version: {}'.format(torch.__version__))\n",
        "print('GPU 사용 가능 여부: {}'.format(torch.cuda.is_available()))\n",
        "\n",
        "print(torch.cuda.get_device_name(0))\n",
        "print(torch.cuda.device_count())\n",
        "\n",
        "# GPU 사용 가능 여부에 따라 device 정보 저장\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkfIDrwBwix5"
      },
      "source": [
        "from easydict import EasyDict as eDict\n",
        "\n",
        "def getArg():\n",
        "\targ = eDict()\n",
        "\n",
        "\targ.batch = 32\n",
        "\targ.epoch = 20\n",
        "\targ.lr = 1e-4\n",
        "\targ.seed = 21\n",
        "\targ.save_capacity = 5\n",
        "\t\n",
        "\targ.train_image_root = \"../input/train2014\"\n",
        "\targ.train_mask_root = \"../input/train_mask\"\n",
        "\targ.val_image_root = \"../input/val2014\"\n",
        "\targ.val_mask_root = \"../input/val_mask\"\n",
        "\targ.output_path = \"../output\"\n",
        "\n",
        "\targ.train_worker = 8\n",
        "\targ.valid_worker = 4\n",
        "\targ.test_worker = 4\n",
        "\n",
        "\targ.wandb = True\n",
        "\targ.wandb_project = \"alchera\"\n",
        "\targ.wandb_entity = \"cv4\"\n",
        "\n",
        "\targ.custom_name = \"sample\"\n",
        "\t\n",
        "\targ.TTA = True\n",
        "\targ.test_batch = 1\n",
        "\targ.csv_size = 256\n",
        "\n",
        "\treturn arg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-p3qno88wjH6"
      },
      "source": [
        "# seed 고정\n",
        "random_seed = 42\n",
        "torch.manual_seed(random_seed)\n",
        "torch.cuda.manual_seed(random_seed)\n",
        "torch.cuda.manual_seed_all(random_seed) # if use multi-GPU\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "np.random.seed(random_seed)\n",
        "random.seed(random_seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rtxm6WVNwmeY"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWqzIgvGwoLA"
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "\n",
        "category_names = [\n",
        "    'Background', 'Body', 'RightHand', 'LeftHand', 'LeftFeet', 'RightFeet', \n",
        "    'RightThigh', 'LeftThigh', 'RightCalf', 'LeftCalf', 'LeftArm', 'RightArm', \n",
        "    'LeftForeArm', 'RightForeArm','Head'\n",
        "    ]\n",
        "\n",
        "def get_classname(classID, cats):\n",
        "    for i in range(len(cats)):\n",
        "        if cats[i]['id']==classID:\n",
        "            return cats[i]['name']\n",
        "    return \"None\"\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    \"\"\"COCO format\"\"\"\n",
        "    image_names = []\n",
        "    num_classes = 15\n",
        "    def __init__(self, image_root, mask_root=None, mode='train', transform=None):\n",
        "        super().__init__()\n",
        "        self.mode = mode\n",
        "        self.image_root = image_root # original images\n",
        "        self.mask_root = mask_root\n",
        "        self.transform = transform\n",
        "        self.setup()\n",
        "\n",
        "    def setup(self):\n",
        "        \"\"\"\n",
        "        saves path of each images\n",
        "        \"\"\"\n",
        "        self.image_names = os.listdir(self.image_root)\n",
        "\n",
        "    def __getitem__(self, index: int):\n",
        "        \n",
        "        images = cv2.imread(os.path.join(self.image_root, self.image_names[index]))\n",
        "        images = cv2.cvtColor(images, cv2.COLOR_BGR2RGB) #FIXME albu issue\n",
        "\n",
        "        if (self.mode in ('train', 'val')):\n",
        "            # imagename에서 확장자 떼고 .png 붙이기\n",
        "            file_name = os.path.splitext(self.image_names[index])[0]\n",
        "            if self.mode == 'train':\n",
        "                file_name += \".png\"\n",
        "            if self.mode == 'val':\n",
        "                file_name += \".grayscale.png\"\n",
        "            masks = cv2.imread(os.path.join(self.mask_root, file_name), cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "            # transform -> albumentations 라이브러리 활용\n",
        "            if self.transform is not None:\n",
        "                transformed = self.transform(image=images, mask=masks)\n",
        "                images = transformed[\"image\"]\n",
        "                masks = transformed[\"mask\"]\n",
        "            return images, masks\n",
        "        \n",
        "        if self.mode == 'test':\n",
        "            # transform -> albumentations 라이브러리 활용\n",
        "            if self.transform is not None:\n",
        "                transformed = self.transform(image=images)\n",
        "                images = transformed[\"image\"]\n",
        "            image_name = os.path.splitext(self.image_names[index])[0]\n",
        "            return images, image_name\n",
        "    \n",
        "    def __len__(self) -> int:\n",
        "        # 전체 dataset의 size를 return\n",
        "        return len(self.image_names)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amyeUlcDxVJ4"
      },
      "source": [
        "# Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3XAeSaTIxUbO"
      },
      "source": [
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import ttach as tta\n",
        "# https://albumentations-demo.herokuapp.com/\n",
        "\n",
        "def getTransform():\n",
        "\n",
        "  train_transform = A.Compose([\n",
        "                              A.Resize(512, 512, p=1.0),\n",
        "                              A.Flip(),\n",
        "                              A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "                              ToTensorV2(),\n",
        "                              ])\n",
        "\n",
        "  val_transform = A.Compose([\n",
        "                              A.Resize(512, 512, p=1.0),\n",
        "                              A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "                            ToTensorV2(),\n",
        "                            ])\n",
        "\n",
        "  return train_transform, val_transform\n",
        "\n",
        "\n",
        "def getInferenceTransform():\n",
        "\n",
        "  test_transform = A.Compose([\n",
        "                            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "                           ToTensorV2(),\n",
        "                           ])\n",
        "\n",
        "  tta_transform = tta.Compose(\n",
        "    [\n",
        "        tta.HorizontalFlip(),\n",
        "        tta.Rotate90(angles=[0, 180]),\n",
        "        tta.Scale(scales=[1, 2, 4]),\n",
        "        tta.Multiply(factors=[0.9, 1, 1.1]),        \n",
        "    ]\n",
        ")\n",
        "\n",
        "                        \n",
        "  return test_transform, tta_transform"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9CZr3Crwxe6"
      },
      "source": [
        "# DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7T8P8IR8wxOn"
      },
      "source": [
        "from torch.utils.data.dataloader import DataLoader\n",
        "\n",
        "# collate_fn needs for batch\n",
        "def collate_fn(batch):\n",
        "    return tuple(zip(*batch))\n",
        "\n",
        "def getDataloader(trainDataset, validDataset, batch, trainWorker, validWorker):\n",
        "\n",
        "\ttrainDataloader = DataLoader(trainDataset, batch_size=batch, shuffle=True, pin_memory=True, num_workers=trainWorker, collate_fn=collate_fn)\n",
        "\tvalidDataloader = DataLoader(validDataset, batch_size=batch, shuffle=False,pin_memory=True, num_workers=validWorker, collate_fn=collate_fn)\n",
        "\n",
        "\treturn trainDataloader, validDataloader\n",
        "\n",
        "def getInferenceDataloader(dataset, batch, num_worker):\n",
        "\n",
        "\treturn DataLoader(dataset, batch_size=1, num_workers=num_worker, shuffle= False,collate_fn=collate_fn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYuOQYI1xGi-"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-iHSlJ8xLXI"
      },
      "source": [
        "import segmentation_models_pytorch as smp\n",
        "\n",
        "# https://smp.readthedocs.io/en/latest/index.html\n",
        "# https://smp.readthedocs.io/en/latest/encoders_timm.html\n",
        "# timm encoder 쓸땐 encoder name에 tu- 붙이기\n",
        "\n",
        "def getModel():\n",
        "\t\n",
        "\tmodel = smp.Unet(\n",
        "\t\t\tencoder_name=\"resnet18\",\n",
        "\t\t\tencoder_weights=\"imagenet\",\n",
        "\t\t\tin_channels=3,\n",
        "\t\t\tclasses=15\n",
        "\t\t)\n",
        "\t\n",
        "\treturn model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNPFBPdUxYPi"
      },
      "source": [
        "## Loss, Optimizer, Schedular"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mQO3uQHxPi8"
      },
      "source": [
        "from torch import nn\n",
        "\n",
        "def getLoss():\n",
        "\tcriterion = nn.CrossEntropyLoss()\n",
        "\n",
        "\treturn criterion"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brxYOGl9xNYH"
      },
      "source": [
        "import torch\n",
        "\n",
        "#https://sanghyu.tistory.com/113\n",
        "#https://gaussian37.github.io/dl-pytorch-lr_scheduler/\n",
        "\n",
        "def getOptAndScheduler(model, lr):\n",
        "\n",
        "\toptimizer = torch.optim.Adam(params = model.parameters(), lr=lr, weight_decay=1e-5)\n",
        "\tscheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer,T_max=10,eta_min=1e-5)\n",
        "\n",
        "\treturn optimizer, scheduler\t"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-sdBA_Kxobl"
      },
      "source": [
        "# Start Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJT-eSZhyJMN"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from utils.utils import add_hist, label_accuracy_score\n",
        "from utils.wandb_method import WandBMethod\n",
        "from utils.tqdm import TQDM\n",
        "from utils.save_helper import SaveHelper\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "\n",
        "def train(num_epochs, model, train_loader, val_loader, criterion, optimizer, scheduler, saved_dir, save_capacity, device, doWandb):\n",
        "    n_class = 15\n",
        "    scaler = GradScaler(enabled=True)\n",
        "\n",
        "    saveHelper = SaveHelper(save_capacity, saved_dir)\n",
        "    mainPbar = TQDM.makeMainProcessBar(num_epochs)\n",
        "\n",
        "    for epoch in mainPbar:\n",
        "        model.train()\n",
        "        pbar = TQDM.makePbar(train_loader, epoch, True)\n",
        "\n",
        "        hist = np.zeros((n_class, n_class))\n",
        "        for step, (images, masks) in enumerate(pbar):\n",
        "            images = torch.stack(images)       \n",
        "            masks = torch.stack(masks).long() \n",
        "            \n",
        "            # gpu 연산을 위해 device 할당\n",
        "            images, masks = images.to(device), masks.to(device)\n",
        "            \n",
        "            # device 할당\n",
        "            model = model.to(device)\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            with autocast(True):\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, masks)\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "\n",
        "            # scheduler.step() \n",
        "\n",
        "            # auxiliary head가 포함됐을 때 mask만 추출\n",
        "            if isinstance(outputs,tuple):\n",
        "                outputs = outputs[0]    \n",
        "            outputs = torch.argmax(outputs, dim=1).detach().cpu().numpy()\n",
        "            \n",
        "            masks = masks.detach().cpu().numpy()\n",
        "            \n",
        "            hist = add_hist(hist, masks, outputs, n_class=n_class)\n",
        "            acc, acc_cls, acc_clsmean, mIoU, fwavacc, IoU = label_accuracy_score(hist)\n",
        "\n",
        "            TQDM.setPbarPostInStep(pbar, acc,acc_clsmean,loss,mIoU)\n",
        "\n",
        "            if doWandb:\n",
        "                WandBMethod.trainLog(loss, acc, scheduler.get_last_lr())\n",
        "\n",
        "        avrg_loss ,mIoU = validation(epoch, model, val_loader, criterion, device, doWandb)\n",
        "        TQDM.setMainPbarPostInValid(mainPbar,avrg_loss)\n",
        "\n",
        "        if saveHelper.checkBestIoU(mIoU, epoch):\n",
        "            TQDM.setMainPbarDescInSaved(mainPbar,epoch,mIoU)\n",
        "            saveHelper.removeModel()\n",
        "            saveHelper.saveModel(epoch,model,optimizer,scheduler)\n",
        "\n",
        "        # Scheduler는 epoch당 step\n",
        "        scheduler.step() \n",
        "\n",
        "def validation(epoch, model, valid_loader, criterion, device, doWandb):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        n_class = 15\n",
        "        total_loss = 0\n",
        "        total_mIoU = 0\n",
        "        cnt = 0\n",
        "        \n",
        "        hist = np.zeros((n_class, n_class))\n",
        "\n",
        "        pbar = TQDM.makePbar(valid_loader,epoch,False)\n",
        "\n",
        "\n",
        "        # len(pbar) 중 랜덤하게 정수 뽑고 해당 step일 때 이미지 그룹 찝어다가 이미지를 doWandb에 넣어줘\n",
        "        targetStep = WandBMethod.pickImageStep(len(pbar))\n",
        "        targetImages, targetOutputs, targetMasks = None, None, None\n",
        "\n",
        "        for step, (images, masks) in enumerate(pbar):\n",
        "            \n",
        "            images = torch.stack(images)       \n",
        "            masks = torch.stack(masks).long()  \n",
        "\n",
        "            images, masks = images.to(device), masks.to(device)            \n",
        "            \n",
        "            model = model.to(device)\n",
        "            \n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, masks)\n",
        "            \n",
        "            # auxiliary head가 포함됐을 때 mask만 추출\n",
        "            if isinstance(outputs,tuple):\n",
        "                outputs = outputs[0]    \n",
        "            \n",
        "            outputs = torch.argmax(outputs, dim=1).detach().cpu().numpy()\n",
        "            masks = masks.detach().cpu().numpy()\n",
        "            \n",
        "            hist = add_hist(hist, masks, outputs, n_class=n_class)\n",
        "            acc, acc_cls, acc_clsmean, mIoU, fwavacc, IoU = label_accuracy_score(hist)\n",
        "\n",
        "\n",
        "            total_loss += loss\n",
        "            total_mIoU += mIoU\n",
        "            cnt += 1\n",
        "\n",
        "            TQDM.setPbarPostInStep(pbar,acc,acc_clsmean,loss,total_mIoU/cnt)\n",
        "\n",
        "            # 여러개의 epoch 중 랜덤으로 뽑아 wandb에 전송하는 용도\n",
        "            if step==targetStep:\n",
        "                targetImages, targetOutputs, targetMasks = images.detach().cpu().numpy(), outputs, masks\n",
        "\n",
        "        avrg_loss = total_loss / cnt\n",
        "        avrg_mIoU = total_mIoU / cnt\n",
        "\n",
        "        if doWandb:\n",
        "            WandBMethod.validLog(IoU, acc_cls, acc_clsmean, acc, avrg_mIoU, targetImages, targetOutputs, targetMasks)\n",
        "      \n",
        "        \n",
        "    return avrg_loss, avrg_mIoU\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vexdZJs-xqbw"
      },
      "source": [
        "arg = getArg()\n",
        "\n",
        "train_transform, val_transform = getTransform()\n",
        "\n",
        "train_dataset = CustomDataset(image_root=arg.train_image_root, mask_root=arg.train_mask_root, mode='train', transform=train_transform)\n",
        "val_dataset = CustomDataset(image_root=arg.val_image_root, mask_root=arg.val_mask_root, mode='val', transform=val_transform)\n",
        "\n",
        "trainLoader, valLoader = getDataloader(train_dataset, val_dataset, arg.batch, arg.train_worker, arg.valid_worker)\n",
        "\n",
        "model = getModel()\n",
        "criterion = getLoss()\n",
        "optimizer, scheduler = getOptAndScheduler(model, arg.lr)\n",
        "\n",
        "outputPath = os.path.join(arg.output_path, arg.custom_name)\n",
        "\n",
        "# output Path 내 설정 저장\n",
        "i = 2\n",
        "while os.path.exists(outputPath):\n",
        "    outputPath = outputPath + \"_\" + str(i)\n",
        "    i += 1\n",
        "\n",
        "shutil.copytree(f\"custom/{custom_dir}\",outputPath)\n",
        "os.makedirs(outputPath+\"/models\")\n",
        "\n",
        "# wandb\n",
        "if arg.wandb:\n",
        "    from utils.wandb_method import WandBMethod\n",
        "    WandBMethod.login(arg, model, criterion)\n",
        "\n",
        "train(arg.epoch, model, trainLoader, valLoader, criterion, optimizer,scheduler, outputPath, arg.save_capacity, device, arg.wandb)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}